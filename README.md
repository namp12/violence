# Nh·∫≠n D·∫°ng B·∫°o L·ª±c Trong Video Gi√°m S√°t Tr∆∞·ªùng H·ªçc

H·ªá th·ªëng nh·∫≠n d·∫°ng h√†nh vi b·∫°o l·ª±c (x√¥ ƒë·∫©y, ƒë√°nh nhau) trong video gi√°m s√°t tr∆∞·ªùng h·ªçc s·ª≠ d·ª•ng m√¥ h√¨nh **3D Convolutional Neural Network (CNN 3D)**.

## üìã M·ª•c L·ª•c

- [T√≠nh NƒÉng](#-t√≠nh-nƒÉng)
- [Y√™u C·∫ßu H·ªá Th·ªëng](#-y√™u-c·∫ßu-h·ªá-th·ªëng)
- [C√†i ƒê·∫∑t](#-c√†i-ƒë·∫∑t)
- [C·∫•u Tr√∫c D·ª± √Ån](#-c·∫•u-tr√∫c-d·ª±-√°n)
- [H∆∞·ªõng D·∫´n S·ª≠ D·ª•ng](#-h∆∞·ªõng-d·∫´n-s·ª≠-d·ª•ng)
- [K·∫øt Qu·∫£](#-k·∫øt-qu·∫£)
- [Tham Kh·∫£o](#-tham-kh·∫£o)

## ‚ú® T√≠nh NƒÉng

- ‚úÖ X·ª≠ l√Ω video v√† tr√≠ch xu·∫•t frames t·ª± ƒë·ªông
- ‚úÖ Chia d·ªØ li·ªáu th√†nh train/validation/test (70/15/15)
- ‚úÖ Ki·∫øn tr√∫c CNN 3D t·ªëi ∆∞u v·ªõi 4 convolutional blocks
- ‚úÖ Data augmentation (flip, rotation, brightness)
- ‚úÖ Training v·ªõi callbacks (ModelCheckpoint, EarlyStopping, ReduceLR, TensorBoard)
- ‚úÖ ƒê√°nh gi√° chi ti·∫øt v·ªõi confusion matrix v√† classification report
- ‚úÖ Inference tr√™n video m·ªõi (single ho·∫∑c batch mode)

## üíª Y√™u C·∫ßu H·ªá Th·ªëng

- **Python**: 3.8 tr·ªü l√™n
- **RAM**: T·ªëi thi·ªÉu 8GB (khuy·∫øn ngh·ªã 16GB)
- **GPU**: Khuy·∫øn ngh·ªã (NVIDIA v·ªõi CUDA support) cho training nhanh
- **Disk Space**: T·ªëi thi·ªÉu 10GB ƒë·ªÉ l∆∞u tr·ªØ d·ªØ li·ªáu v√† models

## üöÄ C√†i ƒê·∫∑t

### B∆∞·ªõc 1: Clone ho·∫∑c t·∫£i d·ª± √°n

```bash
cd e:/nhan_dien_danhnhau
```

### B∆∞·ªõc 2: C√†i ƒë·∫∑t dependencies

```bash
pip install -r requirements.txt
```

> **L∆∞u √Ω**: N·∫øu s·ª≠ d·ª•ng GPU, c·∫ßn c√†i ƒë·∫∑t CUDA v√† cuDNN t∆∞∆°ng th√≠ch v·ªõi TensorFlow version.

### B∆∞·ªõc 3: Ki·ªÉm tra c√†i ƒë·∫∑t

```bash
python -c "import tensorflow as tf; print('TensorFlow version:', tf.__version__); print('GPU available:', tf.config.list_physical_devices('GPU'))"
```

## üìÅ C·∫•u Tr√∫c D·ª± √Ån

```
nhan_dien_danhnhau/
‚îú‚îÄ‚îÄ data/                          # D·ªØ li·ªáu
‚îÇ   ‚îú‚îÄ‚îÄ raw/                       # [T·ª± t·∫°o] Video g·ªëc
‚îÇ   ‚îú‚îÄ‚îÄ processed/                 # [T·ª± ƒë·ªông] D·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ val/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test/
‚îÇ   ‚îî‚îÄ‚îÄ frames/                    # [T·ª± ƒë·ªông] Frames t·∫°m th·ªùi
‚îú‚îÄ‚îÄ models/                        # Models v√† logs
‚îÇ   ‚îú‚îÄ‚îÄ saved_models/              # [T·ª± ƒë·ªông] Models ƒë√£ train
‚îÇ   ‚îú‚îÄ‚îÄ checkpoints/               # [T·ª± ƒë·ªông] Training checkpoints
‚îÇ   ‚îî‚îÄ‚îÄ logs/                      # [T·ª± ƒë·ªông] TensorBoard logs
‚îú‚îÄ‚îÄ scripts/                       # Scripts ch√≠nh
‚îÇ   ‚îú‚îÄ‚îÄ data_preprocessing.py      # X·ª≠ l√Ω d·ªØ li·ªáu
‚îÇ   ‚îú‚îÄ‚îÄ train.py                   # Training
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py                # ƒê√°nh gi√°
‚îÇ   ‚îî‚îÄ‚îÄ predict.py                 # D·ª± ƒëo√°n
‚îú‚îÄ‚îÄ src/                           # Source code
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cnn3d.py              # Ki·∫øn tr√∫c CNN 3D
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dataset.py            # Dataset loader
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ video_utils.py        # Video processing
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ config.py             # Config loader
‚îÇ       ‚îî‚îÄ‚îÄ metrics.py            # Metrics
‚îú‚îÄ‚îÄ config.yaml                    # C·∫•u h√¨nh ch√≠nh
‚îú‚îÄ‚îÄ requirements.txt               # Dependencies
‚îî‚îÄ‚îÄ README.md                      # T√†i li·ªáu n√†y
```

## üìñ H∆∞·ªõng D·∫´n S·ª≠ D·ª•ng

### 1Ô∏è‚É£ Chu·∫©n B·ªã D·ªØ Li·ªáu

B·∫°n ƒë√£ c√≥ s·∫µn dataset trong `Real Life Violence Dataset/`. D·ªØ li·ªáu g·ªìm:
- `Violence/` - 1000 videos b·∫°o l·ª±c
- `NonViolence/` - 1000 videos kh√¥ng b·∫°o l·ª±c

### 2Ô∏è‚É£ Ti·ªÅn X·ª≠ L√Ω D·ªØ Li·ªáu

Script n√†y s·∫Ω:
- Tr√≠ch xu·∫•t 16 frames t·ª´ m·ªói video
- Resize v·ªÅ 112x112 pixels
- Normalize pixel values
- Chia th√†nh train (70%), validation (15%), test (15%)

```bash
python scripts/data_preprocessing.py
```

**Output**: D·ªØ li·ªáu ƒë∆∞·ª£c l∆∞u d∆∞·ªõi d·∫°ng `.npy` files trong `data/processed/`

> ‚è±Ô∏è **Th·ªùi gian**: ~20-30 ph√∫t cho 2000 videos (t√πy CPU)

### 3Ô∏è‚É£ Training Model

```bash
# Training v·ªõi config m·∫∑c ƒë·ªãnh
python scripts/train.py

# Training v·ªõi custom epochs v√† batch size
python scripts/train.py --epochs 30 --batch_size 16
```

**Tham s·ªë quan tr·ªçng trong `config.yaml`**:
- `batch_size`: 8 (m·∫∑c ƒë·ªãnh) - Gi·∫£m n·∫øu GPU h·∫øt memory
- `epochs`: 50 (m·∫∑c ƒë·ªãnh)
- `initial_learning_rate`: 0.0001

**Theo d√µi training**:
```bash
# M·ªü TensorBoard ƒë·ªÉ xem training progress
tensorboard --logdir models/logs
```

Sau ƒë√≥ m·ªü tr√¨nh duy·ªát: `http://localhost:6006`

**Output**:
- Best model: `models/checkpoints/best_model.h5`
- Final model: `models/saved_models/violence_detection_final.h5`
- Training history plot: `models/saved_models/training_history.png`

> ‚è±Ô∏è **Th·ªùi gian**: 
> - **CPU**: 6-10 gi·ªù
> - **GPU (GTX 1060 tr·ªü l√™n)**: 1-2 gi·ªù

### 4Ô∏è‚É£ ƒê√°nh Gi√° Model

```bash
python scripts/evaluate.py --model_path models/saved_models/violence_detection_final.h5
```

**Output**:
- Accuracy, Precision, Recall, F1-Score
- Confusion matrix: `models/evaluation_results/confusion_matrix.png`
- Classification report: `models/evaluation_results/classification_report.txt`

### 5Ô∏è‚É£ D·ª± ƒêo√°n Tr√™n Video M·ªõi

**D·ª± ƒëo√°n 1 video**:
```bash
python scripts/predict.py --video_path path/to/your/video.mp4
```

**D·ª± ƒëo√°n nhi·ªÅu videos (batch mode)**:
```bash
python scripts/predict.py --video_path path/to/videos/ --batch
```

**Output**: Hi·ªÉn th·ªã prediction (Violent/Non-Violent) v√† confidence score

### 6Ô∏è‚É£ Ph√°t Hi·ªán Real-time T·ª´ Webcam

Script n√†y cho ph√©p b·∫°n ph√°t hi·ªán b·∫°o l·ª±c **real-time** t·ª´ camera m√°y t√≠nh:

```bash
# S·ª≠ d·ª•ng camera m·∫∑c ƒë·ªãnh (camera 0)
python scripts/realtime_detect.py

# Ch·ªâ ƒë·ªãnh camera c·ª• th·ªÉ
python scripts/realtime_detect.py --camera 1

# T√πy ch·ªânh model v√† skip frames ƒë·ªÉ tƒÉng t·ªëc
python scripts/realtime_detect.py --model_path models/checkpoints/best_model.h5 --skip_frames 3
```

**Controls**:
- `q`: Tho√°t ch∆∞∆°ng tr√¨nh
- `r`: Reset frame buffer

**T√≠nh nƒÉng**:
- ‚úÖ X·ª≠ l√Ω real-time t·ª´ webcam
- ‚úÖ Buffer 16 frames ƒë·ªÉ ph√¢n t√≠ch
- ‚úÖ Hi·ªÉn th·ªã k·∫øt qu·∫£ v·ªõi m√†u s·∫Øc (ƒê·ªè=Violent, Xanh=Non-Violent)
- ‚úÖ C·∫£nh b√°o nh·∫•p nh√°y khi ph√°t hi·ªán b·∫°o l·ª±c
- ‚úÖ Hi·ªÉn th·ªã confidence score v√† buffer status

> **L∆∞u √Ω**: ƒê·ª£i model training ho√†n t·∫•t tr∆∞·ªõc khi s·ª≠ d·ª•ng t√≠nh nƒÉng n√†y!



V·ªõi dataset Real Life Violence (2000 videos), model ƒë·∫°t ƒë∆∞·ª£c:

| Metric | Target | Typical Result |
|--------|--------|----------------|
| **Accuracy** | > 80% | 82-88% |
| **Precision** | > 75% | 78-85% |
| **Recall** | > 75% | 77-84% |
| **F1-Score** | > 75% | 78-84% |

### Confusion Matrix M·∫´u

```
                 Predicted
              Non-Violent  Violent
Actual
Non-Violent      240         10
Violent           15        235
```

## ‚öôÔ∏è T√πy Ch·ªânh C·∫•u H√¨nh

Ch·ªânh s·ª≠a file `config.yaml` ƒë·ªÉ thay ƒë·ªïi:

**Video processing**:
```yaml
video:
  num_frames: 16          # S·ªë frames extract t·ª´ m·ªói video
  frame_height: 112       # Chi·ªÅu cao frame
  frame_width: 112        # Chi·ªÅu r·ªông frame
```

**Model architecture**:
```yaml
model:
  conv_blocks:            # S·ªë l∆∞·ª£ng v√† c·∫•u h√¨nh conv blocks
    - filters: 32
      kernel_size: [3, 3, 3]
```

**Training**:
```yaml
training:
  batch_size: 8           # K√≠ch th∆∞·ªõc batch
  epochs: 50              # S·ªë epochs
  initial_learning_rate: 0.0001
```

## üêõ X·ª≠ L√Ω L·ªói

### L·ªói: "Out of Memory" khi training
- **Gi·∫£i ph√°p**: Gi·∫£m `batch_size` trong `config.yaml` (v√≠ d·ª•: t·ª´ 8 xu·ªëng 4 ho·∫∑c 2)

### L·ªói: "No module named 'tensorflow'"
- **Gi·∫£i ph√°p**: Ch·∫°y `pip install -r requirements.txt`

### L·ªói: Video kh√¥ng ƒë∆∞·ª£c x·ª≠ l√Ω
- **Nguy√™n nh√¢n**: Video b·ªã l·ªói ho·∫∑c codec kh√¥ng h·ªó tr·ª£
- **Gi·∫£i ph√°p**: Chuy·ªÉn ƒë·ªïi video sang format MP4 (H.264 codec)

### Training r·∫•t ch·∫≠m
- **Gi·∫£i ph√°p**: 
  - Ki·ªÉm tra GPU: `python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"`
  - N·∫øu kh√¥ng c√≥ GPU, training s·∫Ω ch·∫≠m h∆°n nhi·ªÅu (~10 l·∫ßn)

## üìö Tham Kh·∫£o

### Papers
- [Learning Spatiotemporal Features with 3D Convolutional Networks](https://arxiv.org/abs/1412.0767)
- [Two-Stream Convolutional Networks for Action Recognition](https://arxiv.org/abs/1406.2199)

### Datasets
- Real Life Violence Dataset
- Hockey Fight Dataset
- Movies Fight Dataset

## üë• Contributing

N·∫øu mu·ªën ƒë√≥ng g√≥p v√†o d·ª± √°n:
1. Fork repository
2. T·∫°o branch m·ªõi
3. Commit changes
4. Push v√† t·∫°o Pull Request

## üìÑ License

MIT License - T·ª± do s·ª≠ d·ª•ng cho m·ª•c ƒë√≠ch h·ªçc t·∫≠p v√† nghi√™n c·ª©u.

---

**Developed by**: D·ª± √°n Nh·∫≠n D·∫°ng B·∫°o L·ª±c  
**Last Updated**: January 2026
#   v i o l e n c e  
 